mean(1,23,45,12,32,78,100,43,68, 89,68)
mean(c(1,23,45,12,32,78,100,43,68,89,68))
# Load functions
source('functions.R')
# Load the data
emails = read.csv("D:/Data/energy_bids.csv", stringsAsFactors=FALSE)
str(emails)
emails$email[1]
str(emails$email[1)]
str(emails$email[1)])
strwrap(emails$email[1)])
strwrap(emails$email[1])
strwrap(emails$email[2])
table(emails$responsive)
library(tm)
library(SnowballC)
# Preprocess
corpus = Corpus(VectorSource(emails$email)) # Create corpus
corpus # Look at corpus
writeLines(as.character(corpus[[1]])) # Look at corpus
corpus <-tm_map(corpus, content_transformer(tolower)) # Convert to lower-case
corpus = tm_map(corpus, removePunctuation) # Remove punctuation
#stopwords("english")[1:200] # Look at stop words
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english"))) # Remove stopwords and apple
corpus = tm_map(corpus, stemDocument) # Stem document
writeLines(as.character(corpus[[1]]))
corpus[[1]]
emails$email[1]
corpus$email[1]
writeLines(as.character(corpus[[1]]))
writeLines(as.character(strwrap(corpus[[1]])))
# Create matrix
dtm = DocumentTermMatrix(corpus)
dtm
# Remove sparse terms
dtm = removeSparseTerms(dtm, 0.97)
dtm
# Create data frame
labeledTerms = as.data.frame(as.matrix(dtm))
# Add in the outcome variable
labeledTerms$responsive = emails$responsive
str(labeledTerms)
dtm
frequencies = DocumentTermMatrix(corpus) # Create matrix
frequencies # view  matrix
frequencies = removeSparseTerms(frequencies, 0.97) # Remove sparse terms (remove 97 of the terms%)
frequencies # view sparse terms
Bag of words
dtm = DocumentTermMatrix(corpus) # Create matrix
dtm # view  matrix
dtm = removeSparseTerms(dtm, 0.97) # Remove sparse terms (remove 97 of the terms%)
dtm # view sparse terms
df = as.data.frame(as.matrix(dtm)) #Convert to a data frame
View(df)
colnames(df) = make.names(colnames(df)) # Make all variable names R-friendly
df$responsive <-emails$responsive # Add dependent variable
df <-cleanit(df)
colnames(df) = make.names(colnames(df))
# Split the data to  build models
library(caTools)
set.seed(144)
split = sample.split(df$responsive, SplitRatio = 0.7)
dfTrain = subset(df, split==TRUE)
dfTest = subset(df, split==FALSE)
colnames(dfTrain) = make.names(colnames(dfTrain))
colnames(dfTest) = make.names(colnames(dfTest))
# clean things up
rm(df, emails,corpus,dtm,split)
corprm(frequencies)
rm(frequencies)
rm(labeledTerms)
# Build a CART model
library(rpart)
library(rpart.plot)
CARTTrain = rpart(responsive ~ ., data=dfTrain, method="class")
prp(CARTTrain)
# Determine the Majority
bl <-table(dfTrain$responsive)
majority<-ifelse(bl[1]>bl[2],0,1)
# Fill in a prediction for the majority of the training set
predictTrainBase <-rep(majority,nrow(dfTrain))
#Compare
cm <- table(dfTrain$responsive,predictTrainBase,exclude=NULL)
addmargins(cm)
getstats(cm)
predictCARTTrain = predict(CARTTrain,type="class")
cm<-table(dfTrain$responsive, predictCARTTrain)
addmargins(cm)
getstats(cm)
# Baseline on Testing data
# Determine the Majority
bl <-table(dfTest$responsive)
majority<-ifelse(bl[1]>bl[2],0,1)
# Fill in a prediction for the majority
predictTestBase <-rep(majority,nrow(dfTest))
#Compare
cm <- table(dfTest$responsive,predictTestBase,exclude=NULL)
addmargins(cm)
getstats(cm)
# Evaluate the performance of the model on TEST SET
predictCARTTest = predict(CARTTrain, newdata=dfTest, type="class")
cm<-table(dfTest$responsive, predictCARTTest)
thres=0.5
addmargins(cm)
getstats(cm)
cm<-table(dfTest$responsive, predictCARTTest)
addmargins(cm)
library(ROCR)
predROCR = prediction(pred.prob, dfTest$responsive)
predROCR = prediction(CARTTrain, dfTest$responsive)
predROCR = prediction(predictCARTTest, dfTest$responsive)
predROCR = prediction(predictCARTTest[,2], dfTest$responsive)
predROCR = prediction(predictCARTTest[,2], dfTest$responsive)
predictCARTTest[,2]
predictCARTTest
predictCARTTest[2]
predictCARTTest[,2]
predictCARTTest[1,2]
predictCARTTest[12]
predictCARTTest = predict(CARTTrain, newdata=dfTest)
cm<-table(dfTest$responsive, predictCARTTest)
thres=0.5
predictCARTTest[]
predROCR = prediction(predictCARTTest[,2], dfTest$responsive)
perfROCR = performance(predROCR, "tpr", "fpr")
plot(perfROCR, colorize=TRUE)
# Compute AUC
performance(predROCR, "auc")@y.values
plot(ROCRperfTest, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
plot(perfROCR, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
performance(predROCR, "auc")@y.values
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
auc<-performance(predROCR, "auc")@y.values
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
auc
# Compute AUC
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
# Compute AUC
auc = as.numeric(performance(predROCR, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
# Evaluate the performance of the model on TEST SET
predictCARTTest = predict(CARTTrain, newdata=dfTest)
cm<-table(dfTest$responsive, predictCARTTest)
thres=0.2
addmargins(cm)
getstats(cm)
predictCARTTest = predict(CARTTrain, newdata=dfTest)
cm<-table(dfTest$responsive, predictCARTTest)
thres=0.15
predictCARTTest = predict(CARTTrain, newdata=dfTest)
cm<-table(dfTest$responsive, predictCARTTest)
thres=0.15
addmargins(cm)
getstats(cm)
# ROC curve
library(ROCR)
predROCR = prediction(predictCARTTest[,2], dfTest$responsive)
plot(, colorize=TRUE)
plot(perfROCR, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
# Compute AUC
auc = as.numeric(performance(predROCR, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
library(randomForest)
set.seed(144)
forestFit = randomForest(responsive~., data = dfTrain)
PredictForest = predict(forestFit, newdata = dfTest)
cm <- table(dfTest$responsive, PredictForest)
addmargins(cm)
getstats(cm)
?randomForest
vu = varUsed(forestFit, count=TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(forestFit$forest$xlevels[vusorted$ix]))
# Load functions
source('functions.R')
library(plyr)
library(ggplot2)
library(gridExtra)
library(caret)
library(tm)
library(RWeka)
library(R.utils)
library(stringi)
library(stringr)
library(SnowballC)
library(RColorBrewer)
library(magrittr)
library(wordcloud)
library(textcat)
library(xtable)
library(markovchain)
install.packages("markovchain")
install.packages("wordcloud")
install.packages("textcat")
# Load functions
source('functions.R')
library(plyr)
library(ggplot2)
library(gridExtra)
library(caret)
library(tm)
library(RWeka)
library(R.utils)
library(stringi)
library(stringr)
library(SnowballC)
library(RColorBrewer)
library(magrittr)
library(wordcloud)
library(textcat)
library(xtable)
library(markovchain)
fileLineNum = CalculateTextFileLines("D:/DataCapstone/data/en_US.blogs.txt")
fileWordCount = CountWordsInTextFile("D:/DataCapstone/data/en_US.blogs.txt")
blackList = read.csv("D:/DataCapstone/data/Terms-to-Block.csv", skip=4)
blackList = blackList[,2]
blackList = gsub(",","",blackList)
setwd("C:/Users/bryan_000/Documents/GitHub/Capstone2/App4/")
source("Utilities.R")
fileLineNum = CalculateTextFileLines("D:/DataCapstone/data/en_US.blogs.txt")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
setwd("~/GitHub/MyWork")
source('~/.active-rstudio-document', echo=TRUE)
a<- c(0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0)
b<- c(0,1,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0)
c<-a-b
c
d=c*c
d
sqrt(2)
plot (a,b)
scatterplot(a,b)
scatter(a,b)
# Load functions
source('functions.R')
# After following the steps in the video, load the data into R
# After following the steps in the video, load the data into R
movies = read.table(""D:/Data/emovieLens.txt", header=FALSE, sep="|",quote="\"")
movies = read.table("D:/Data/emovieLens.txt", header=FALSE, sep="|",quote="\"")
m
e
movies = read.table("D:/Data/u.txt", header=FALSE, sep="|",quote="\"")
str(movies)
colnames(movies) = c("ID", "Title", "ReleaseDate", "VideoReleaseDate", "IMDB", "Unknown", "Action", "Adventure", "Animation", "Childrens", "Comedy", "Crime", "Documentary", "Drama", "Fantasy", "FilmNoir", "Horror", "Musical", "Mystery", "Romance", "SciFi", "Thriller", "War", "Western")
str(movies)
movies$ID = NULL
movies$ReleaseDate = NULL
movies$VideoReleaseDate = NULL
movies$IMDB = NULL
movies = unique(movies)
# Take a look at our data again:
str(movies)
# Load functions
source('functions.R')
# Load the data into R
movies = read.table("D:/Data/u.txt", header=FALSE, sep="|",quote="\"")
str(movies)
# Add column names
colnames(movies) = c("ID", "Title", "ReleaseDate", "VideoReleaseDate", "IMDB", "Unknown", "Action", "Adventure", "Animation", "Childrens", "Comedy", "Crime", "Documentary", "Drama", "Fantasy", "FilmNoir", "Horror", "Musical", "Mystery", "Romance", "SciFi", "Thriller", "War", "Western")
# Remove unnecessary variables
movies$ID = NULL
movies$ReleaseDate = NULL
movies$VideoReleaseDate = NULL
movies$IMDB = NULL
# Remove duplicates
movies = unique(movies)
# Take a look at our data again:
str(movies)
table (movies)
table (movies$Comedy)
table (movies$Western)
table (movies$Romance, movies$Drama)
distances = dist(movies[2:20], method = "euclidean")
# Hierarchical clustering
clusterMovies = hclust(distances, method = "ward")
plot(clusterMovies)
clusterGroups = cutree(clusterMovies, k = 10)
tapply(movies$Action, clusterGroups, mean)
tapply(movies$Romance, clusterGroups, mean)
tapply(movies$Action, clusterGroups, mean)
tapply(movies$Romance, clusterGroups, mean)
tapply(movies$Adventure, clusterGroups, mean)
tapply(movies$Animation, clusterGroups, mean)
tapply(movies$Action, clusterGroups, mean)
tapply(movies$Romance, clusterGroups, mean)
tapply(movies$Adventure, clusterGroups, mean)
tapply(movies$Animation, clusterGroups, mean)
tapply(movies$Childrens, clusterGroups, mean)
tapply(movies$Comedy, clusterGroups, mean)
tapply(movies$Crime, clusterGroups, mean)
tapply(movies$Action, clusterGroups, mean)
tapply(movies$Romance, clusterGroups, mean)
tapply(movies$Adventure, clusterGroups, mean)
tapply(movies$Animation, clusterGroups, mean)
tapply(movies$Childrens, clusterGroups, mean)
tapply(movies$Comedy, clusterGroups, mean)
tapply(movies$Crime, clusterGroups, mean)
tapply(movies$Documentary, clusterGroups, mean)
tapply(movies$Drama, clusterGroups, mean)
tapply(movies$Fantasy, clusterGroups, mean)
tapply(movies$FilmNoir, clusterGroups, mean)
tapply(movies$Horror, clusterGroups, mean)
tapply(movies$Musical, clusterGroups, mean)
tapply(movies$Mystery, clusterGroups, mean)
tapply(movies$SciFi, clusterGroups, mean)
tapply(movies$Thriller, clusterGroups, mean)
tapply(movies$War, clusterGroups, mean)
tapply(movies$western, clusterGroups, mean)
tapply(movies$Western, clusterGroups, mean)
subset(movies, Title=="Men in Black (1997)")
clusterGroups[257]
cluster2 = subset(movies, clusterGroups==2)
# Look at the first 10 titles in this cluster:
cluster2$Title[1:10]
cluster2$Title[1:]
cluster2$Title[1:10]
cluster2$Title
# Assign points to clusters
twoGroups = cutree(clusterMovies, k = 2)
twoGroups
tapply(movies$Action, twoGroups, mean)
tapply(movies$Romance, twoGroups, mean)
tapply(movies$Adventure, twoGroups, mean)
tapply(movies$Animation, twoGroups, mean)
tapply(movies$Childrens, twoGroups, mean)
tapply(movies$Comedy, twoGroups, mean)
tapply(movies$Crime, twoGroups, mean)
tapply(movies$Documentary, twoGroups, mean)
tapply(movies$Drama, twoGroups, mean)
tapply(movies$Fantasy, twoGroups, mean)
tapply(movies$FilmNoir, twoGroups, mean)
tapply(movies$Horror, twoGroups, mean)
tapply(movies$Musical, twoGroups, mean)
tapply(movies$Mystery, twoGroups, mean)
tapply(movies$SciFi, twoGroups, mean)
tapply(movies$Thriller, twoGroups, mean)
tapply(movies$War, twoGroups, mean)
tapply(movies$Western, twoGroups, mean)
library(rUnemploymentData)
data(df_county_unemployment)
ylab="Percent Unemployment")
boxplot(df_county_unemployment[, c(-1, -2, -3)],main="USA County Unemployment Data",xlab="Year",ylab="Percent Unemployment")
county_unemployment_choropleth(year=2013)
animated_county_unemployment_choropleth()
county_unemployment_choropleth(year=2009)
[1,-3]*[4,5]
c[1,-3]*c[4,5]
(1,-3)*(4,5)
as.matrix(1,-3)*as.matrix(4,5)
a <-as.martix(1,-3)
a <-as.matrix(1,-3)
a
a<-matrix(data = c(1,-3), nrow = 1, ncol = 2, byrow = TRUE, dimnames = NULL)
a
b<-matrix(data = c(4,5), nrow = 1, ncol = 2, byrow = TRUE, dimnames = NULL)
a*b
a<-matrix(data = c(3,4,5), nrow = 1, ncol = 3, byrow = TRUE, dimnames = NULL)
b<-matrix(data = c(1,2,3), nrow = 1, ncol = 3, byrow = TRUE, dimnames = NULL)
a*b
sum(a)
sum(a*b)
dotproduct <- function(dataf, v2) {
>        apply(t(t(as.matrix(a)) * v2),1,sum) #contorted!
>    }
>
>    df = data.frame(a=c(1,2,3),b=c(4,5,6))
>    vec = c(4,5)
>    dotproduct(df, vec)
dotproduct <- function(dataf, v2) {
apply(t(t(as.matrix(a)) * v2),1,sum) #contorted!
}
df = data.frame(a=c(1,2,3),b=c(4,5,6))
vec = c(4,5)
View(df)
df = data.frame(a=3),b=5,c=5)
df = data.frame(a=3,b=5,c=5)
vec = c(1,2,3)
dotproduct(df, vec)
df = data.frame(a=1,b=-3)
vec = c(4,5)
dotproduct(df, vec)
sum(df*vec)
b<-matrix(data = c(1,2,3), nrow = 1, ncol = 3, byrow = TRUE, dimnames = NULL)
x<-matrix(data = c(1,2,3,4,5,6), nrow = 2, ncol = 3, byrow = TRUE, dimnames = NULL)
x
y<-matrix(data = c(1,2,3,4,5,6), nrow = 2, ncol = 3, byrow = FALSE, dimnames = NULL)
y
y<-matrix(data = c(1,2,3,4,5,6), nrow = 3, ncol = 2, byrow = FALSE, dimnames = NULL)
y
y<-matrix(data = c(1,2,3,4,5,6), nrow = 3, ncol = 2, byrow = TRUE, dimnames = NULL)
y
x*y
matrix(x)*matrix(y)
y<-matrix(data = c(1,2,3), nrow = 1, ncol = 1, byrow = TRUE, dimnames = NULL)
y
y<-matrix(data = c(1,2,3), nrow = 1, ncol = 1, byrow = FALSE, dimnames = NULL)
y
y<-matrix(data = c(1,2,3), nrow = 1, ncol = 1, byrow = TRUE, dimnames = NULL)
y
y<-matrix(data = c(1,2,3), nrow = 3, ncol = 1, byrow = FALSE, dimnames = NULL)
y
x<-matrix(data = c(1,2,3), nrow = 1, ncol = 3, byrow = FALSE, dimnames = NULL)
x
matrix(x)*matrix(y)
x*y
matrix(x)*matrix(y)
library(rUnemploymentData)
data(df_county_unemployment)
View(df_county_unemployment)
county_unemployment_choropleth(year=2008)
data
df_county_unemployment["region"==2105]
df_county_unemployment[region==2105]
df<- df_county_unemployment
df[,0]
df[[0]]
df[[,0]]
df[,0]
View(df)
df[[,1]]
df[,1]
df[[,1]==5106]
df[[,1 ==5106]
]
df[[,1]==5106
df[[,1]]==5106
df[[1]==5106
df[1]==5106
county_unemployment_choropleth(year=2008)
boxplot(df_county_unemployment[, c(-1, -2, -3)],main="USA County Unemployment Data",xlab="Year",ylab="Percent Unemployment")
county_unemployment_choropleth(region=2105)
county_unemployment_choropleth(year=2008)
#animated_county_unemployment_choropleth()
notin<-df[1]==c(2105,2198,15005,2195,2275)
notin
df2<-df[notin]
df2<-df[notin,]
View(df2)
source('functions.R')
# Load the data
df<-data(df_county_unemployment)
df<-cleanit(df)
summary(df)
df<-cleanit(df_county_unemployment)
summary(df)
# count blanks remove blanks
barplot(colSums(!is.na(df)))
#df <- na.omit(df)
colSums(!is.na(df))
colSums(!is.na(df))
df <- na.omit(df)
colSums(!is.na(df))
county_unemployment_choropleth(year=2008)
source('functions.R')
# Load the data
data(df_county_unemployment)
df_county_unemployment<-cleanit(df_county_unemployment)
summary(df)
summary(df_county_unemployment)
#df <- na.omit(df)
colSums(!is.na(df))
barplot(colSums(!is.na(df_county_unemployment)))
#df <- na.omit(df)
colSums(!is.na(df_county_unemployment))
boxplot(df_county_unemployment[, c(-1, -2, -3)],main="USA County Unemployment Data",xlab="Year",ylab="Percent Unemployment")
county_unemployment_choropleth(year=2008)
?rUnemploymentData
load("D:/Data/censusdata/admin1.regions.rdata")
View(admin1.regions)
source('~/.active-rstudio-document', echo=TRUE)
build_county_df
build_county_df()
source('~/.active-rstudio-document', echo=TRUE)
build_county_df()
?trim
?str
trim?
?trim
?rtrim
install.packages("stringr")
install.packages("stringr")
source('~/.active-rstudio-document', echo=TRUE)
build_county_df()
library(strngr)
library(stringr)
build_county_df()
warnings()
install.packages('pollstR', dependencies = TRUE)
library("pollstR")
library(stringi)
charts <- pollstr_charts()
str(charts)
charts <- pollstr_charts()
str(charts)
us_charts <- pollstr_charts(state = "US")
obama_favorable <- pollstr_chart('obama-favorable-rating')
print(obama_favorable)
(ggplot(obama_favorable[["estimates_by_date"]], aes(x = date, y = value, color = choice))
+ geom_line())
library(ggplot)
install.packages("ggplot")
