addmargins(cm)
getstats(cm)
# Pull out mistakes
subset(dfTest, predictTest >= thres & notfullypaid == 0)
subset(dfTest, predictTest <= thres & notfullyaid == 1)
#Add predicted risk to table
dfTest$predictedrisk<-predictTest
# Build Receiver Operator Charastics ROC
library(ROCR)
# Prediction function
ROCRpredTest = prediction(predictTest,dfTest$notfullypaid)
# Performance function
ROCRperfTest = performance(ROCRpredTest, "tpr", "fpr")
# Plot ROC curve and add AUC
plot(ROCRperfTest, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
# Calculate orofit and loss
#c<-10 # Amount
#r<-.06 # Interst rate per time period (years)
#t<-3 # Time period (years)
#total<- c * exp(r*t)
#profit <- c * (exp(r*t) - 1)
#rbind (Loan=c,TotalPayments=total,Profit=profit)
#Add profit column to test set
dfTest$profit = exp(dfTest$intrate*3) - 1
dfTest$profit[dfTest$notfullypaid == 1] = -1
max(dfTest$profit)*10
# Find high interst loans
# Average profit from high interest gropu
# Percents
mean(dfTestHigh$profit)
x<-table(dfTestHigh$notfullypaid)
dfTestHigh <-subset(dfTest, intrate> .15)
addmargins(x)
dfTestFinal<-subset(dfTestHigh, predictedrisk<=cutoff)
# Percents
x<-table(dfTestFinal$notfullypaid)
addmargins(x)
cutoff <-sort(dfTestHigh$predictedrisk, decreasing=FALSE)[100]
sum(dfTestFinal$profit)
prop.table(x)
prop.table(x)
cutoff
table(dfTrain$notfullypaid)
# Fill in a prediction
predictTestBase <-rep(0,nrow(dfTrain))
z <-table(dfTrain$notfullypaid)
paste(dfTest,depvar,sep=' ~ ')
ls
paste("dfTest",depvar,sep='$')
f9<-paste("dfTest",depvar,sep='$')
cm <- table(f9,predictTestBase, exclude=NULL)
f9<-paste("dfTrain",depvar,sep='$')
cm <- table(f9,predictTestBase, exclude=NULL)
f9
predictTestBase <-rep(0,nrow(dfTrain))
#Compare
cm <- table(f9,predictTestBase, exclude=NULL)
addmargins(cm)
getstats(cm)
z <-table(f9)
z
z <-table(get(f9))
paste(dfTrain,paste(depvar,collapse=' - '),sep='$')
paste('dfTrain',paste(depvar,collapse=' - '),sep='$')
f
f10<-paste('dfTrain',paste(depvar,collapse=' - '),sep='$')
f10
get(f10)
f10
cm <- table(dfTrain$notfullypaid,predictTestBase, exclude=NULL)
addmargins(cm)
getstats(cm)
z <-table(dfTrain$notfullypaid)
z
z[1]
ifesle(z[1]>z[2],maj=0,maj=1)
ifelse(z[1]>z[2],maj=0,maj=1)
ifelse(z[1]>z[2],0,1)
z[]
ifelse(z[1]>z[2],0,1)
majority<-ifelse(z[1]>z[2],0,1)
predictTestBase <-rep(majority,nrow(dfTrain))
#Compare
cm <- table(dfTrain$notfullypaid,predictTestBase, exclude=NULL)
addmargins(cm)
getstats(cm)
# multicolinearity
# Baseline on Training data
# Determine the Majority
bl <-table(dfTrain$notfullypaid)
majority<-ifelse(bl[1]>bl[2],0,1)
# Fill in a prediction for the majority
predictTestBase <-rep(majority,nrow(dfTrain))
#Compare
cm <- table(dfTrain$notfullypaid,predictTestBase, exclude=NULL)
addmargins(cm)
getstats(cm)
# multicolinearity
# Exclude dep var column and facotr column
cor(dfTrain[,c(-2,-14)])
pc <- princomp(dfTrain[,c(-2,-14)], cor=TRUE, scores=TRUE)
summary(pc)
plot(pc,type="l")
biplot(pc)
install.packages(c("arulesViz", "BH", "chron", "DiceDesign", "diptest", "dplyr", "earth", "effects", "ergm", "ergm.count", "FactoMineR", "gtools", "HH", "httr", "igraph", "latentnet", "lme4", "lmtest", "manipulate", "mda", "mnormt", "mosaic", "party", "plotmo", "plyr", "polyclip", "RcmdrPlugin.HH", "RcmdrPlugin.RMTCJags", "RcmdrPlugin.UCA", "RcppArmadillo", "rmarkdown", "robustbase", "rversions", "scales", "sem", "seriation", "shiny", "shinydashboard", "sp", "spatstat", "ssanv", "stringi", "strucchange", "tergm", "testthat", "vcd", "XML"))
install.packages(c("arulesViz", "BH", "chron", "DiceDesign",
View(dfTest)
source('functions.R')
# Load the data
df<-read.csv("D:/Data/ClaimsData.csv")
df<-cleanit(df)
summary(df)
table(df$bucket2009)/nrow(df)
x<-  table(df$bucket2009)
addmargins(x)
prop.table(x)
barplot(colSums(!is.na(df)))
colSums(!is.na(df)
colSums(!is.na(df)
colSums(!is.na(df))
library(caTools)
set.seed(88)
split = sample.split(df$bucket2009, SplitRatio = 0.6)
dfTrain = subset(df, split==TRUE)
dfTest = subset(df, split==FALSE)
rm(df,split)
dfTest = subset(df, split==FALSE)
#Logistic Regression Problem
# Load functions
source('functions.R')
# Load the data
df<-read.csv("D:/Data/ClaimsData.csv")
df<-cleanit(df)
summary(df)
# Percentage of patients in each cost bucket
x<-  table(df$bucket2009)
addmargins(x)
prop.table(x)
# count blanks remove blanks
barplot(colSums(!is.na(df)))
#df <- na.omit(df)
colSums(!is.na(df))
library(caTools)
set.seed(88)
split = sample.split(df$bucket2009, SplitRatio = 0.6)
dfTrain = subset(df, split==TRUE)
dfTest = subset(df, split==FALSE)
rm(df,split)
summary(dfTrain)
cm<-table(dfTrain$bucket2009,dfTrain$bucket2008)
addmargins(cm)
getstats(cm)
cm<-table(dfTest$bucket2009,dfTest$bucket2008)
addmargins(cm)
getstats(cm)
#getstats(cm)
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
PenaltyMatrix
pm = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
as.matrix(x)*pm
as.matrix(cm)*pm
sum(as.matrix(cm)*pm/nrows(dfTest))
sum(as.matrix(cm)*pm/nrow(dfTest))
bl <-table(dfTrain$bucket2009)
bl
majority<-ifelse(bl[1]>bl[2],0,1)
predictTestBase <-rep(majority,nrow(dfTrain))
cm <- table(dfTrain$notfullypaid,predictTestBase, exclude=NULL)
bl <-table(dfTesting$bucket2009)
bl <-table(dfTest$bucket2009)
majority<-ifelse(bl[1]>bl[2],0,1)
# Fill in a prediction for the majority
predictTestBase <-rep(majority,nrow(dfTest))
#Compare
cm <- table(dfTest$bucket2009,predictTestBase, exclude=NULL)
addmargins(cm)
getstats(cm)
pm = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
cm
pm = matrix(c(0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
pm = matrix(c(0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=2)
pm = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
pm
pm = matrix(c(0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
pm = matrix(c(6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
pm
cm
pm = matrix(c(6,4,2,0,1,8,6,4,2,0,0,0), byrow=TRUE, nrow=5)
pm = matrix(c(6,4,2,0,1,8,6,4,2,0,0,0), byrow=TRUE, nrow=6)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
pm = matrix(c(0,0,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=6)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
pm
pm = matrix(c(6,4,2,0,1,8,6,4,2,0,0,0), byrow=TRUE, nrow=6)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
pm
cm
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
PenaltyMatrix
pm <- matrix(c(0,1,2,2,4,2,6,4,8,6,0,0), byrow=TRUE, nrow=6)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
cm <- table(dfTest$bucket2009,predictTestBase, exclude=NULL)
# Advanced model
#cm<-table(dfTest$bucket2009,dfTest$bucket2008)
addmargins(cm)
getstats(cm)
# Make penalty matrix
pm = matrix(c(6,4,2,0,1,8,6,4,2,0,0,0), byrow=TRUE, nrow=6)
pm <- matrix(c(0,1,2,2,4,2,6,4,8,6,0,0), byrow=TRUE, nrow=6)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
#Logistic Regression Problem
# Load functions
source('functions.R')
# Load the data
df<-read.csv("D:/Data/ClaimsData.csv")
df<-cleanit(df)
summary(df)
# Percentage of patients in each cost bucket
x<-  table(df$bucket2009)
addmargins(x)
prop.table(x)
# count blanks remove blanks
barplot(colSums(!is.na(df)))
#df <- na.omit(df)
colSums(!is.na(df))
Impute Values
# Split the data
library(caTools)
set.seed(88)
split = sample.split(df$bucket2009, SplitRatio = 0.6)
dfTrain = subset(df, split==TRUE)
dfTest = subset(df, split==FALSE)
rm(df,split)
# Baseline on Testing data
# Determine the Majority
bl <-table(dfTest$bucket2009)
majority<-ifelse(bl[1]>bl[2],0,1)
# Fill in a prediction for the majority
predictTestBase <-rep(majority,nrow(dfTest))
#Compare
cm <- table(dfTest$bucket2009,predictTestBase, exclude=NULL)
# Advanced model
#cm<-table(dfTest$bucket2009,dfTest$bucket2008)
addmargins(cm)
getstats(cm)
# Make penalty matrix
pm = matrix(c(6,4,2,0,1,8,6,4,2,0,0,0), byrow=TRUE, nrow=6)
pm <- matrix(c(0,1,2,2,4,2,6,4,8,6,0,0), byrow=TRUE, nrow=6)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
x<-  table(df$bucket2009)
addmargins(x)
prop.table(x)
# count blanks remove blanks
# Baseline on Testing data
# Determine the Majority
bl <-table(dfTrain$bucket2009)
majority<-ifelse(bl[1]>bl[2],0,1)
majority
bl <-table(dfTrain$bucket2009)
majority<-ifelse(bl[1]>bl[2],0,1)
majority
bl
# Fill in a prediction for the majority
predictTrainBase <-rep(majority,nrow(dfTrain))
#Compare
cm <- table(dfTrain$bucket2009,predictTrainBase, exclude=NULL)
# Advanced model
#cm<-table(dfTest$bucket2009,dfTest$bucket2008)
#Add margins and compute stats
addmargins(cm)
getstats(cm)
# Make penalty matrix
pm = matrix(c(6,4,2,0,1,8,6,4,2,0,0,0), byrow=TRUE, nrow=6)
pm <- matrix(c(0,1,2,2,4,2,6,4,8,6,0,0), byrow=TRUE, nrow=6)
# Multiple cm * pm
sum(as.matrix(cm)*pm/nrow(dfTest))
# Load necessary libraries
library(rpart)
library(rpart.plot)
# CART model
trainTree = rpart(depvar ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005)
depvar <- 'bucket2009'
indepvars <-c('.')
exclude <- c('reimbursement2009') # numerical variables to exclude from using all
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f2 <- paste(f1,paste(exclude,collapse=' - '),sep=' - ')
trainTree = rpart(f2, data=dfTrain, method="class", cp=0.00005)
prp(ClaimsTree)
prp(trainTree)
summary(traintree)
summary(trainTree)
predictTest = predict(trainTree, newdata = dfTest, type = "class")
predictTest
table(predictTest)
table(dfTest$bucket2009, predictTest)
cm=table(dfTest$bucket2009, predictTest)
addmargins(cm)
getstats(cm)
# Penalty Matrix
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
# Penalty Error
as.matrix(table(dfTest$bucket2009, predictTest))*PenaltyMatrix
sum(as.matrix(table(dfTest$bucket2009, predictTest))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(table(dfTest$bucket2009, predictTest))*PenaltyMatrix)/nrow(dfTest)
trainTree = rpart(f2, data=dfTrain, method="class", cp=0.00005, parms=list(loss=PenaltyMatrix))
prp(trainTree)
# Make predictions
predictTest = predict(trainTree, newdata = dfTest, type = "class")
cm=table(dfTest$bucket2009, predictTest)
#Add margins and compute stats
addmargins(cm)
getstats(cm)
as.matrix(table(dfTest$bucket2009, predictTest))*PenaltyMatrix
sum(as.matrix(table(dfTest$bucket2009, predictTest))*PenaltyMatrix)/nrow(dfTest)
summary(predictTest)
summary(trainTree)
#Logistic Regression Problem
# Load functions
source('functions.R')
# Load the data
df<-read.csv("D:/Data/Gerber.csv")
df<-cleanit(df)
summary(df)
x<-  table(df$control)
addmargins(x)
prop.table(x)
x<-  table(df$voting)
addmargins(x)
prop.table(x)
# count blanks remove blanks
barplot(colSums(!is.na(df)))
#df <- na.omit(df)
colSums(!is.na(df))
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
depvar <- 'voting'
indepvars <-c('.')
exclude <- c('hawthrone','civicduty','neighbors','self') # numerical variables to exclude from using all
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f2 <- paste(f1,paste(exclude,collapse=' - '),sep=' - ')
table(f1)
depvar <- 'voting'
indepvars <-c('hawthrone','civicduty','neighbors','self')
exclude <- c('hawthrone','civicduty','neighbors','self') # numerical variables to exclude from using all
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f2 <- paste(f1,paste(exclude,collapse=' - '),sep=' - ')
table(f1)
xtabs(f1)
xtabs(f1, data=dfTest)
xtabs(f1, data=df)
depvar <- 'voting'
indepvars <-c('hawthorne','civicduty','neighbors','self')
exclude <- c('hawthrone','civicduty','neighbors','self') # numerical variables to exclude from using all
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f2 <- paste(f1,paste(exclude,collapse=' - '),sep=' - ')
xtabs(f1,df)
xtabs(indepvars,df)
p
p
p
p
depvar <- 'voting'
indepvars <-c('hawthorne','civicduty','neighbors','self')
exclude <- c('hawthrone','civicduty','neighbors','self') # numerical variables to exclude from using all
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f2 <- paste(f1,paste(exclude,collapse=' - '),sep=' - ')
xtabs(indepvars,df)
xtabs(f1,df)
depvar <- 'voting'
indepvars <-c('voting','hawthorne','civicduty','neighbors','self')
exclude <- c('hawthrone','civicduty','neighbors','self') # numerical variables to exclude from using all
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f2 <- paste(f1,paste(exclude,collapse=' - '),sep=' - ')
xtabs(f1,df)
xtabs('~voting','hawthorne','civicduty','neighbors','self',df)
xtabs(~'voting','hawthorne','civicduty','neighbors','self',df)
xtabs(~'voting'+'hawthorne'+'civicduty'+'neighbors'+'self',df)
xtabs('voting'+'hawthorne'+'civicduty'+'neighbors'+'self',df)
xtabs(~'voting'+'hawthorne'+'civicduty'+'neighbors'+'self',df)
xtabs('voting'~'hawthorne'+'civicduty'+'neighbors'+'self',df)
depvar <- 'voting'
indepvars <-c('hawthorne','civicduty','neighbors','self')
exclude <- c('hawthrone','civicduty','neighbors','self') # numerical variables to exclude from using all
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f2 <- paste(f1,paste(exclude,collapse=' - '),sep=' - ')
xtabs('voting'~'hawthorne'+'civicduty'+'neighbors'+'self',df)
xtabs(f1,df)
table(indepvars)
table(df$voting)
table(df$voting,df$hawthorne)
table(df$voting,df$hawthorne,df$civicduty)
ftable(table(df$voting,df$hawthorne,df$civicduty))
ftable(table(df$voting,df$hawthorne,df$civicduty,df$neighbors))
ftable(table(df$voting,df$hawthorne,df$civicduty,df$neighbors,df$self))
ftable(xtabs(df$voting,df$hawthorne,df$civicduty,df$neighbors,df$self))
ftable(xtabs(df$voting~df$hawthorne+df$civicduty+df$neighbors+df$self))
d
depvar <- 'voting'
indepvars <-c('hawthorne','civicduty','neighbors','self')
exclude <- c() # numerical variables to exclude from using all
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f2 <- paste(f1,paste(exclude,collapse=' - '),sep=' - ')
fit<-glm(f1,data=df,family=binomial)
summary(fit)
bl <-table(df$voting)
majority<-ifelse(bl[1]>bl[2],0,1)
# Fill in a prediction for the majority
predictTrainBase <-rep(majority,nrow(df))
#Compare
cm <- table(df$voting,predictTrainBase, exclude=NULL)
addmargins(cm)
getstats(cm)
thres = .3
predictTrain <- predict(fit, type="response")
cm <- table(df$voting,predictTrain>thres)
addmargins(cm)
getstats(cm)
thres = .5
predictTrain <- predict(fit, type="response")
cm <- table(df$voting,predictTrain>thres)
addmargins(cm)
getstats(cm)
thres = .5
predictTrain <- predict(fit, type="response")
cm <- table(df$voting,predictTrain>thres)
addmargins(cm)
getstats(cm)
thres = .49
predictTrain <- predict(fit, type="response")
cm <- table(df$voting,predictTrain>thres)
addmargins(cm)
getstats(cm)
# Prediction function
ROCRpredTrain = prediction(predictTrain,df$voting)
# Performance function
ROCRperfTrain = performance(ROCRpredTrain, "tpr", "fpr")
# Plot ROC curve and add AUC
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
# Build Receiver Operator Charastics ROC
library(ROCR)
# Prediction function
ROCRpredTrain = prediction(predictTrain,df$voting)
# Performance function
ROCRperfTrain = performance(ROCRpredTrain, "tpr", "fpr")
# Plot ROC curve and add AUC
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
# Load CART packages
library(rpart)
library(rpart.plot)
# Build a regression tree
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=df)
prp(latlontree)
latlontree
prp(CARTmodel)
summary(CARTmodel)
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=df,cp=0.0)
prp(CARTmodel)
CARTmodel01 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=df)
prp(CARTmodel01)
CARTmodel02 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=df,cp=0.0)
prp(CARTmodel02)
CARTmodel01 = rpart(voting ~ civicduty + hawthorne + self + neighbors+ sex, data=df,cp=0.0)
prp(CARTmodel01)
CARTmodel04 = rpart(voting ~ civicduty + hawthorne + self + neighbors + control+sex, data=df,cp=0.0)
prp(CARTmodel04)
CARTmodel05 = rpart(voting ~control, data=df,cp=0.0)
prp(CARTmodel05)
prp(CARTmodel05)
CARTmodel06 = rpart(voting ~ control+sex, data=df,cp=0.0)
prp(CARTmodel06)
prp(CARTmodel05"digits = 6")
prp(CARTmodel05, digits = 6)
CARTmodel06 = rpart(voting ~ control+sex, data=df,cp=0.0)
prp(CARTmodel06,digits = 6)
abs(.296638-.34)
abs(.290456-.302795)
abs(.290456-.334176)
abs(.302795-.345818)
abs(.290456-.334176) - abs(.302795-.345818)
fit2<-glm(voting ~ control+sex,data=df,family=binomial)
summary(fit2)
Possibilities = data.frame(sex=c(0,0,1,1),control=c(0,1,0,1))
predict(fit2, newdata=Possibilities, type="response")
abs(.302795-0.29080645)
abs(0.29080645-.302795)
abs(0.29080645-.290456)
fit3<-glm(voting ~ control+sex+sex:control,data=df,family=binomial)
summary(fit3)
predict(fit3, newdata=Possibilities, type="response")
abs(0.29045578 -.290456)
source('~/GitHub/MyWork/EdExAssignment5.R', echo=TRUE)
