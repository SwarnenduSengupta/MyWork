tpr <-cm[2,2]/(cm[2,2]+cm[2,1])
# Specificity a.k.a. TNR
tnr <- cm[1,1]/(cm[1,1]+cm[1,2])
rbind(Sensitivity=tpr, Specificity=tnr)
thres<-0.2
cm<-table(dfTrain$poorcare, predictTrain > thres)
#Sensititvity a.k.a TPR
tpr <-cm[2,2]/(cm[2,2]+cm[2,1])
# Specificity a.k.a. TNR
tnr <- cm[1,1]/(cm[1,1]+cm[1,2])
rbind(Sensitivity=tpr, Specificity=tnr)
?performance
performance(ROCRpred, "tpr", "fpr")
performance(ROCRpred, "tpr", "spec")
performance(ROCRpred, "sens", "spec")
sum(performance(ROCRpred, "sens", "spec"))
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1
abline(coef=c(0,1)
abline(coef=c(0,1)
sum(performance, "sens", "spec"))
abline(coef=c(0,1)
abline(coef=c(0,1))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
ROCRpredTrain = prediction(predictTrain, dfTrain$poorcare)
# Performance function
ROCRperfTrain = performance(ROCRpredTrain, "tpr", "fpr")
# Plot ROC curve
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
auc
text(6, 2, "the text is CENTERED around (x,y) = (6,2) by default",cex = .8)
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(6, 2, "the text is CENTERED around (x,y) = (6,2) by default",cex = .8)
text(6, 2, IIIIIIIII,cex = .8)
text(6, 2, auc,cex = .8)
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(6, 2, auc,cex = .99)
text(6, 2, auc)
text(1, 1, auc)
text(2, 1, auc)
# Plot ROC curve
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(2, 1, auc)
abline(coef=c(0,1))
text(0, 1, auc)
abline(coef=c(0,1))
text(0.5, 1, auc)
text(0.5, 1, "AUC:" auc)
# Plot ROC curve
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(0.5, 1, "AUC:")
text()
abline(coef=c(0,1))
text(0.6,1, round(auc,2))
# Plot ROC curve
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
abline(coef=c(0,1))
# Plot ROC curve and add AUC
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
thres<-0.7
cm<-table(dfTrain$poorcare, predictTrain > thres)
#Sensititvity a.k.a TPR
tpr <-cm[2,2]/(cm[2,2]+cm[2,1])
# Specificity a.k.a. TNR
tnr <- cm[1,1]/(cm[1,1]+cm[1,2])
rbind(Sensitivity=tpr, Specificity=tnr)
# Build Receiver Operator Charastics ROC
library(ROCR)
# Prediction function
ROCRpredTrain = prediction(predictTrain, dfTrain$poorcare)
# Performance function
ROCRperfTrain = performance(ROCRpredTrain, "tpr", "fpr")
# Plot ROC curve and add AUC
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
predictTest= predict(fit, type="response")
# Make predictions on training set
predictTest= predict(fit, type="response")
# Analyze predictions
summary(predictTest)
tapply(predictTest, dfTest$poorcare, mean)
predictTest= predict(fit, type="response", newdata=dfTest)
summary(predictTest)
tapply(predictTest, dfTest$poorcare, mean)
# Analyze predictions
summary(predictTest)
tapply(predictTest, dfTest$poorcare, mean)
# Confusion matrix for threshold
thres<-0.2
cm<-table(dfTest$poorcare, predictTest > thres)
#Sensititvity a.k.a TPR
tpr <-cm[2,2]/(cm[2,2]+cm[2,1])
# Specificity a.k.a. TNR
tnr <- cm[1,1]/(cm[1,1]+cm[1,2])
rbind(Sensitivity=tpr, Specificity=tnr)
# Prediction function
ROCRpredTest = prediction(predictTest, dfTest$poorcare)
# Performance function
ROCRperfTest = performance(ROCRpredTest, "tpr", "fpr")
# Plot ROC curve and add AUC
plot(ROCRperfTest, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
# Compute out-of-sample R^2
SSE = sum((predictTest - dfTest$poorcare)^2)
SST = sum((mean(dfTrain$poorcare) - dfTest$poorcare)^2)
R2 = 1 - SSE/SST
R2
# Compute the RMSE
RMSE = sqrt(SSE/nrow(dfTest))
RMSE
summary(fit)
source('~/GitHub/MyWork/EdExUnit3InCLass.R', echo=TRUE)
plot(dfTrain$officevisits,dfTrain$narcotics,pch=15, col = rgb(0,1,dfTrain$poorcare))
ROCRpredTest = prediction(predictTest, dfTest$depvar)
ROCRpredTest = prediction(predictTest, paste("dfTest$",depvar)
)
ROCRpredTest = prediction(predictTest, paste("dfTest$",depvar))
ROCRpredTrain = prediction(predictTrain, paste(dfTrain,depvar,sep='$'))
ROCRpredTrain = prediction(predictTrain, paste("dfTrain",depvar,sep='$'))
ROCRpredTrain = prediction(predictTrain, paste("dfTrain",get(depvar),sep='$'))
ROCRpredTrain = prediction(predictTrain, dfTrain$poorcare)
ROCRperfTrain = performance(ROCRpredTrain, "tpr", "fpr")
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
fit
# Build Receiver Operator Charastics ROC
library(ROCR)
# Prediction function
ROCRpredTrain = prediction(predictTrain, dfTrain$poorcare)
# Performance function
ROCRperfTrain = performance(ROCRpredTrain, "tpr", "fpr")
# Plot ROC curve and add AUC
plot(ROCRperfTrain, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
abline(coef=c(0,1))
auc = as.numeric(performance(ROCRpredTrain, "auc")@y.values)
text(0.5, 1, "AUC:")
text(0.6,1, round(auc,4))
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
ROCRpredTest = prediction(predictTest,dfTest$poorcare)
source('~/.active-rstudio-document', echo=TRUE)
mean(dfTrain$poorcare)
source('~/GitHub/MyWork/TableExampleCourseraClass.R', echo=TRUE)
oddsratio(x)
riskratio(x)
prop.table(addmargins(x),1) #row
prop.table(addmargins(x),2) #column
source('~/GitHub/MyWork/EdExUnit3InCLass.R', echo=TRUE)
prob.tables(cm)
prop.tables(cm)
prop.table(cm)
prop.table(cm,1)
prop.table(cm,2)
cm
addmargins(cm)
addmargins(cm,1)
addmargins(cm,2)
addmargins(cm,3)
addmargins(cm)
thres<-0.7
cm<-table(dfTrain$poorcare, predictTrain > thres)
addmargins(cm)
thres<-0.3
cm<-table(dfTrain$poorcare, predictTrain > thres)
addmargins(cm)
# Confusion matrix for threshold
thres<-0.3
cm<-table(dfTest$poorcare, predictTest > thres)
addmargins(cm)
cm<-table(dfTest$poorcare, predictTest > thres)
addmargins(cm)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/GitHub/MyWork/Vets.R', echo=TRUE)
x
oddsratio.wald(x) ## Or You can use epitab(x)
rm(df,df0,df1)
# Load functions
source('functions.R')
# Load the libraries
library(e1071)
library(epitools)
# Build the data
# Place the referent group first or use relevel command in R
# Place the dependent variable 0 group first
df0<- data.frame(cbind (Ind=rep("NotVet",35),Dep=rep("NotSick",35)))
df1<- data.frame(cbind (Ind=rep("NotVet",15),Dep=rep("Sick",15)))
total <- rbind(df0, df1)
df0<- data.frame(cbind (Ind=rep("Vet",10),Dep=rep("NotSick",10)))
df1<- data.frame(cbind (Ind=rep("Vet",40),Dep=rep("Sick",40)))
total <- rbind(total, df0)
total <- rbind(total, df1)
# remove extras
rm(df,df0,df1)
#Build a table
x<-table(total$Dep,total$Ind,deparse.level = 2)
x
addmargins(x)
prop.table(x,1) #row
prop.table(x,2) #column
prop.table(addmargins(x),1) #row
prop.table(addmargins(x),2) #column
#Graphics
mosaicplot(x)
barplot(x)
#Odds ratio and confidence intervals (IF CONTAI 1 NOT SIGN)
oddsratio.wald(x) ## Or You can use epitab(x)
#Chi squared test
chisq.test(x)
chisq.test(x)$expected  # expected counts under the null
chisq.test(x)$observed  # observed counts (same as M)
chisq.test(x)$residuals # Pearson residuals
chisq.test(x)$stdres    # standardized residuals
#Fit the model
fit<-glm(Dep~Ind,data=total,family=binomial(link="logit"))
fit
summary(fit)
cbind(Coeff = coef(fit),confint(fit)) # 95% CI for the coefficients using profiled log-likelihood
cbind(Coeff = coef(fit),confint.default(fit)) # 95% CI for the coefficients using standard errors
exp(cbind(OR = coef(fit), confint(fit))) ## odds ratios and 95% CI together
exp(cbind(OR = coef(fit), confint.default(fit))) ## odds ratios and 95% CI together using standard errors
# Get loglikelihood
logLik(fit)
# Load functions
source('functions.R')
# Load the libraries
library(psych)
library(e1071)
library(caret)
library(fBasics)
# Load the data
#Load the birthweight data (lowbw.csv)
#df<-read.csv(file.choose())
df<-read.csv("D:/Data/lowbwt.csv")
# count blanks remove blanks
colSums(!is.na(df))
#df <- na.omit(df)
#colSums(!is.na(df))
# Clean
df<- cleanit(df)
# remove a column
df$id <-NULL
df$bwt <-NULL
# Create dummies
#df$white <- as.numeric(df$race == 1)
#df$black <- as.numeric(df$race == 2)
#df$other <- as.numeric(df$race == 3)
# Create factor
df$race <- factor(df$race, levels=c(1,2,3),labels=c("white","black","other"))
df$smoke<- factor(df$smoke, levels=c(0,1),labels=c("nonsmoker","smoker"))
df$ht<- factor(df$ht, levels=c(0,1),labels=c("noHT","yesHT"))
df$ui<- factor(df$ui, levels=c(0,1),labels=c("noUI","yesUI"))
df$ptl<- factor(df$ptl, levels=c(0,1),labels=c("noPM","yesPML"))
#Dep and Independent Vars
# define columns we will be working with
depvar <- 'low'
indepvar <- 'race'
indepvars <-c('lwt','race')
# two-way contingency table of categorical outcome and predictors we want
#  to make sure there are not 0 cells
xtabs(~get(depvar) + get(indepvar), data = df)
xtabs(~get(depvar) + get(indepvars), data = df)
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
fit<-step(glm(f1,data=df,family=binomial),direction="both")
summary(fit) # display results
fit<-glm(f1,data=df,family=binomial)
summary(fit) # display results
confint(fit) # 95% CI for the coefficients using profiled log-likelihood
confint.default(fit) # 95% CI for the coefficients using standard errors
#exp(coef(fit)) # exponentiated coefficients a.k.a odds ratios
#exp(confint(fit)) # 95% CI for exponentiated coefficients
exp(cbind(OR = coef(fit), confint(fit))) ## odds ratios and 95% CI together
d<-anova(fit,test='Chisq') # or d<-anova(fit,test='LRT')
d
test<-data.frame(lwt=100,race="black")
fitpred<-predict(fit,test,se.fit=TRUE)
pi <- cbind(Prob=fitpred$fit,LCL=fitpred$fit - fitpred$se.fit*1.96,UCL=fitpred$fit + fitpred$se.fit*1.96)
pi2 <- cbind(Prob=exp(pi[,1])/(1+exp(pi[,1])),LCL=exp(pi[,2])/(1+exp(pi[,2])),UCL=exp(pi[,3])/(1+exp(pi[,3])))
#Note 59% chance of having a low birthweight baby for a black woman with lwt=100
pi
pi2
df<-within(df, {lwd <- ifelse( lwt == 110 | lwt > 110, 0, 1)})
indepvarsinter <-c('lwd','age','lwd*age')
f1 <- paste(depvar,paste(indepvar,collapse=' + '),sep=' ~ ')
f2 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f3 <-paste(depvar,paste(indepvarsinter,collapse=' + '),sep=' ~ ')
indepvar <- 'lwd'
indepvars <-c('lwd','age')
indepvarsinter <-c('lwd','age','lwd*age')
#Paste together dep and independents
f1 <- paste(depvar,paste(indepvar,collapse=' + '),sep=' ~ ')
f2 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
f3 <-paste(depvar,paste(indepvarsinter,collapse=' + '),sep=' ~ ')
fit1<-glm(f1,data=df,family=binomial)
fit2<-glm(f2,data=df,family=binomial)
fit3<-glm(f3,data=df,family=binomial)
reviewit <- function(fit) {
print(summary(fit)) # display results
print(confint(fit)) # 95% CI for the coefficients using profiled log-likelihood
print(confint.default(fit)) # 95% CI for the coefficients using standard errors
print(exp(cbind(OR = coef(fit), confint(fit)))) ## odds ratios and 95% CI together
print(anova(fit,test='Chisq')) # or d<-anova(fit,test='LRT')
# get LR
#d$Deviance
# Get loglikelihood
print(logLik(fit))
}
reviewit(fit1)
reviewit(fit2)
reviewit(fit3)
test2<-data.frame(age=30,lwd=1)
fitpred<-predict(fit3,test2,se.fit=TRUE)
pi <- cbind(Prob=fitpred$fit,LCL=fitpred$fit - fitpred$se.fit*1.96,UCL=fitpred$fit + fitpred$se.fit*1.96)
pi2 <- cbind(Prob=exp(pi[,1])/(1+exp(pi[,1])),LCL=exp(pi[,2])/(1+exp(pi[,2])),UCL=exp(pi[,3])/(1+exp(pi[,3])))
#Note 59% chance of having a low birthweight baby for a black woman with lwt=100
pi
pi2
x<-c(0,1,1)
y<-c(2,2,8)
fit<-lm(y~x )
fit
source('~/.active-rstudio-document', echo=TRUE)
reviewit(fit)
pi <- cbind(Prob=predictTest$fit,LCL=predictTest$fit - predictTest$se.fit*1.96,UCL=predictTest$fit + predictTest$se.fit*1.96)
View(dfTest)
View(dfTrain)
test2<-data.frame(narcotics=3,officevisits=1)
fitpred<-predict(fit,test2,se.fit=TRUE)
pi <- cbind(Prob=fitpred$fit,LCL=fitpred$fit - fitpred$se.fit*1.96,UCL=fitpred$fit + fitpred$se.fit*1.96)
pi2 <- cbind(Prob=exp(pi[,1])/(1+exp(pi[,1])),LCL=exp(pi[,2])/(1+exp(pi[,2])),UCL=exp(pi[,3])/(1+exp(pi[,3])))
#Note 59% chance of having a low birthweight baby for a black woman with lwt=100
pi
pi2
test2<-data.frame(narcotics=3,officevisits=10)
fitpred<-predict(fit,test2,se.fit=TRUE)
pi <- cbind(Prob=fitpred$fit,LCL=fitpred$fit - fitpred$se.fit*1.96,UCL=fitpred$fit + fitpred$se.fit*1.96)
pi2 <- cbind(Prob=exp(pi[,1])/(1+exp(pi[,1])),LCL=exp(pi[,2])/(1+exp(pi[,2])),UCL=exp(pi[,3])/(1+exp(pi[,3])))
#Note 59% chance of having poor care with
pi
pi2
# Make a prediction for
test2<-data.frame(narcotics=2,officevisits=9)
fitpred<-predict(fit,test2,se.fit=TRUE)
pi <- cbind(Prob=fitpred$fit,LCL=fitpred$fit - fitpred$se.fit*1.96,UCL=fitpred$fit + fitpred$se.fit*1.96)
pi2 <- cbind(Prob=exp(pi[,1])/(1+exp(pi[,1])),LCL=exp(pi[,2])/(1+exp(pi[,2])),UCL=exp(pi[,3])/(1+exp(pi[,3])))
#Note 59% chance of having poor care with
pi
pi2
# Make a prediction for
test2<-data.frame(narcotics=2,officevisits=14)
fitpred<-predict(fit,test2,se.fit=TRUE)
pi <- cbind(Prob=fitpred$fit,LCL=fitpred$fit - fitpred$se.fit*1.96,UCL=fitpred$fit + fitpred$se.fit*1.96)
pi2 <- cbind(Prob=exp(pi[,1])/(1+exp(pi[,1])),LCL=exp(pi[,2])/(1+exp(pi[,2])),UCL=exp(pi[,3])/(1+exp(pi[,3])))
#Note 59% chance of having poor care with
pi
pi2
# Compute out-of-sample R^2
SSE = sum((predictTest - dfTest$poorcare)^2)
SST = sum((mean(dfTrain$poorcare) - dfTest$poorcare)^2)
R2 = 1 - SSE/SST
R2
# Compute the RMSE
RMSE = sqrt(SSE/nrow(dfTest))
RMSE
sizes <- factor(c("small", "large", "large", "small", "medium"))
sizes
sizes <- factor(sizes, levels = c("small", "medium", "large"))
sizes
sizes <- ordered(c("small", "large", "large", "small", "medium"))
sizes <- ordered(sizes, levels = c("small", "medium", "large"))
sizes
# Create a factor with the wrong order of levels
sizes <- factor(c("small", "large", "large", "small", "medium"))
sizes
sizes <- relevel(sizes, "medium")
sizes
# Make small first
sizes <- relevel(sizes, "small")
sizes
sizes <- factor(c("small", "large", "large", "small", "medium"),levels = c("small", "medium", "large"))
sizes
sizes <- factor(c("small", "large", "large", "small", "medium"))
sizes
# Create a factor with the wrong order of levels
sizes <- factor(c("small", "large", "large", "small", "medium"))
sizes
sizes <- factor(sizes, levels=rev(levels(sizes)))
sizes
set.seed(123)
x <- rnorm(100)
df <- data.frame(x = x,y = 4 + (1.5*x) + rnorm(100, sd = 2),b = gl(5, 20))
head(df)
str(df)
m1 <- lm(y ~ x + b, data = df)
summary(m1)
df <- within(df, b <- relevel(b, ref = 3))
m2 <- lm(y ~ x + b, data = df)
summary(m2)
cdind(m1,m2)
cbind(m1,m2)
cbind(coef(m1),coef(m2))
rbind(coef(m1),coef(m2))
coef(m1)
coef(m2)
coef(m1)
coef(m2)
```
?gl
#Create a data frame with x,y, and b (b is a factor with 5 levels)
df <- data.frame(x = x,y = 4 + (1.5*x) + rnorm(100, sd = 2),b = gl(5, 20))
m1 <- lm(y ~ x + b, data = df)
summary(m1)
#Just change the referent level for b from b1 to b3
df <- within(df, b <- relevel(b, ref = 3))
m2 <- lm(y ~ x + b, data = df)
summary(m2)
# Dep and Independent Vars define columns we will be working with
depvar <- 'x'
indepvars <-c('y', 'b')
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
set.seed(123)
x <- rnorm(100)
#Create a data frame with x,y, and b (b is a factor with 5 levels.  The first level is the referent group)
df <- data.frame(x = x,y = 4 + (1.5*x) + rnorm(100, sd = 2),b = gl(5, 20))
# Dep and Independent Vars define columns we will be working with
depvar <- 'x'
indepvars <-c('y', 'b')
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
m1 <- lm(f1, data = df)
summary(m1)
df <- within(df, b <- relevel(b, ref = 3))
m2 <- lm(f1 data = df)
summary(m2)
```{r}
coef(m1)
coef(m2)
#Just change the referent level for b from b1 to b3
df <- within(df, b <- relevel(b, ref = 3))
m2 <- lm(f1,data = df)
summary(m2)
```{r}
coef(m1)
coef(m2)
# Dep and Independent Vars define columns we will be working with
depvar <- 'y'
indepvars <-c('x', 'b')
f1 <- paste(depvar,paste(indepvars,collapse=' + '),sep=' ~ ')
m1 <- lm(f1, data = df)
summary(m1)
```
Now alter the factor b in DF by use of the relevel() function:
```{r}
#Just change the referent level for b from b1 to b3
df <- within(df, b <- relevel(b, ref = 3))
m2 <- lm(f1,data = df)
summary(m2)
```
Compare m1 and m2
```{r}
coef(m1)
coef(m2)
```
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
source('~/GitHub/MyWork/EdExUnit3InCLass.R', echo=TRUE)
source('~/GitHub/MyWork/EdExUnit3InCLass.R', echo=TRUE)
source.with.encoding('~/.active-rstudio-document', encoding='UTF-8', echo=TRUE)
reviewit(m1)
reviewit(m2)
outliers(df$x)
outliers(df$y)
makedf(x)
df2<-makedf(df$x)
df3<-makedf(df$y)
plot(df2)
plot(df3)
#Just change the referent level for b from b1 to b3
m3 <- lm(y~x,data = df)
coef(m1)
coef(m2)
coef(m3)
coef(m1)
coef(m2)
coef(m3)
reviewit(m1)
reviewit(m2)
reviewit(m3)
