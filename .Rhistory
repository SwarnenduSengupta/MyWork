setwd("~/GitHub/MyWork")
source('~/GitHub/MyWork/StdOpen.R')
source('~/GitHub/MyWork/StdOpen.R')
install.packages("Rtools")
find_rtools()
find_rtools()
find_rtools()
##Set seed for reproducibility
set.seed(2345)
##Set data directory
##Use my standard openning including call function
if (Sys.info()["sysname"]=="Linux"){
datadir=('/home/bryan/GitHub/Data/')
}else{
datadir=('E:/Data/')
}
source('C:/Users/bryan_000/Documents/GitHub/MyWork/StdOpen.R')
source('C:/Users/bryan/Documents/GitHub/MyWork/StdOpen.R')
---
require(devtools)
install_github('rCharts', 'ramnathv')
library(rCharts)
## Example 1 Facetted Scatterplot
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
## Example 2 Facetted Barplot
hair_eye = as.data.frame(HairEyeColor)
rPlot(Freq ~ Hair | Eye, color = 'Eye', data = hair_eye, type = 'bar')
r1 <- rPlot(mpg ~ wt | am + vs, data = mtcars, type = "point", color = "gear")
r1$print("chart1")
library(ggplot2)
r1 <- rPlot(mpg ~ wt | am + vs, data = mtcars, type = "point", color = "gear")
r1$print("chart1")
r1
call("kernlab")
### finding optimal value of a tuning parameter
sigDist <- sigest(y ~ ., data = dataTrain, frac = 1)
### creating a grid of two tuning parameters, .sigma comes from the earlier line. we are trying to find best value of .C
svmTuneGrid <- data.frame(.sigma = sigDist[1], .C = 2^(-2:7))
##My standard opening
source('C:/Users/bryan/Documents/GitHub/MyWork/StdOpen.R')
##Set destination file for download
spamfile <-paste(datadir,"spamdata.csv",sep = "")
spamnames <-paste(datadir,"spamnames.csv",sep = "")
#Check for the File. If not there, download the data
if (!file.exists(spamfile)) {
file.url <- 'http://thinktostart.com/data/data.csv'
download.file(file.url, spamfile)
}
if (!file.exists(spamnames)) {
file.url <- 'http://thinktostart.com/data/names.csv'
download.file(file.url, spamnames)
}
#Load the two files into R:
spamdataset <- read.csv(spamfile,header=FALSE,sep=";")
spamnames <- read.csv(spamnames,header=FALSE,sep=";")
#Set the names of the spamdataset dataframe:
names(spamdataset) <- sapply((1:nrow(spamnames)),function(i) toString(spamnames[i,1]))
#make column y a factor variable for binary classification (spam or non-spam)
spamdataset$y <- as.factor(spamdataset$y)
#get a sample of 1000 rows
sample <- spamdataset[sample(nrow(spamdataset), 1000),]
#Split the data in dataTrain and dataTest
trainIndex <- createDataPartition(sample$y, p = .8, list = FALSE, times = 1)
dataTrain <- sample[ trainIndex,]
dataTest  <- sample[-trainIndex,]
call("kernlab")
### finding optimal value of a tuning parameter
sigDist <- sigest(y ~ ., data = dataTrain, frac = 1)
### creating a grid of two tuning parameters, .sigma comes from the earlier line. we are trying to find best value of .C
svmTuneGrid <- data.frame(.sigma = sigDist[1], .C = 2^(-2:7))
#Create the SVM model:
x <- train(y ~ .,
data = dataTrain,
method = "svmRadial",
preProc = c("center", "scale"),
tuneGrid = svmTuneGrid,
trControl = trainControl(method = "repeatedcv", repeats = 5,
classProbs =  TRUE))
n.cases <- 240               # Number of points.
n.vars <- 4                  # Number of mutually correlated variables.
set.seed(26)                 # Make these results reproducible.
eps <- rnorm(n.vars, 0, 1/4) # Make "1/4" smaller to *increase* the correlations.
x <- matrix(rnorm(n.cases * (n.vars+2)), nrow=n.cases)
beta <- rbind(c(1,rep(0, n.vars)), c(0,rep(1, n.vars)), cbind(rep(0,n.vars), diag(eps)))
y <- x%*%beta                # The variables.
cor(y)                       # Verify their correlations are as intended.
plot(data.frame(y))          # Show the scatterplot matrix.
# Perform PCA on the first 2, 3, 4, ..., n.vars+1 variables.
p <- lapply(2:dim(beta)[2], function(k) prcomp(y[, 1:k], scale=TRUE))
# Print summaries and display plots.
tmp <- lapply(p, summary)
par(mfrow=c(2,2))
tmp <- lapply(p, plot)
# Scatterplot Matrices from the glus Package
library(gclus)
dta <- mtcars[c(1,3,5,6)] # get data
dta.r <- abs(cor(dta)) # get correlations
dta.col <- dmat.color(dta.r) # get colors
# reorder variables so those with highest correlation
# are closest to the diagonal
dta.o <- order.single(dta.r)
cpairs(dta, dta.o, panel.colors=dta.col, gap=.5,
main="Variables Ordered and Colored by Correlation" )
install.packages("gclus")
# Scatterplot Matrices from the glus Package
library(gclus)
dta <- mtcars[c(1,3,5,6)] # get data
dta.r <- abs(cor(dta)) # get correlations
dta.col <- dmat.color(dta.r) # get colors
# reorder variables so those with highest correlation
# are closest to the diagonal
dta.o <- order.single(dta.r)
cpairs(dta, dta.o, panel.colors=dta.col, gap=.5,
main="Variables Ordered and Colored by Correlation" )
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col="red", size=3)
library(scatterplot3d)
install.packages("scatterplot3d")
library(scatterplot3d)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col="red", size=3)
attach(mtcars)
library(scatterplot3d)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col="red", size=3)
plot3d(wt, disp, mpg, col="red", size=3)
library(rgl)
install.packages("rgl")
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col="red", size=3)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=am, size=3)
ls
mtcars
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=gear, size=3)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=carb, size=6)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=rowname, size=6)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=Rowname, size=6)
?rowname
str(mtcars)
library(mtcars)
df=mtcars
View(df)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=row.names, size=6)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=carbs, size=6)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=carb, size=6)
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=carb, size=6,labels=row.names(mtcars))
# Spinning 3d Scatterplot
library(rgl)
plot3d(wt, disp, mpg, col=carb, size=6,labels=row.names(mtcars))
plot3d(wt, disp, mpg, col=carb, size=6,labels=row.names(mtcars))
3d<-plot3d(wt, disp, mpg, col=carb, size=6,labels=row.names(mtcars))
3d <-plot3d(wt, disp, mpg, col=carb, size=6,labels=row.names(mtcars))
p3d <-plot3d(wt, disp, mpg, col=carb, size=6,labels=row.names(mtcars))
p3d
ibrary(scatterplot3d)
hi <- as.numeric(x[4,1:ncol(x)])
scatterplot3d(ex,qu,hi,pch=20,highlight.3d=T)
library(scatterplot3d)
hi <- as.numeric(x[4,1:ncol(x)])
scatterplot3d(ex,qu,hi,pch=20,highlight.3d=T)
library(rgl)
attach(mtcars)
plot3d(wt, disp, mpg, col="red", size=3)
plot3d(wt, disp, mpg, col=am, size=3)
plot3d(wt, disp, mpg, col=carb, size=3)
plot3d(wt, disp, mpg, col=carb, size=5)
plot3d(wt, mpg, disp, col=carb, size=5)
len(mtcars)
length(mtcars)
str(mtcars)
row.names(mtcars)
library(rgl)
attach(mtcars)
plot3d(wt, mpg, disp, col=carb, size=5)
scatterplot3d(wt,disp,mpg, pch=16, highlight.3d=TRUE,type="h", main="3D Scatterplot")
scatterplot3d(wt,disp,mpg, pch=carb, highlight.3d=TRUE,type="h", main="3D Scatterplot")
scatterplot3d(wt,disp,mpg, pch=carb, col=cyl,type="h", main="3D Scatterplot")
scatterplot3d(wt,disp,mpg, pch=carb, col=am,type="h", main="3D Scatterplot")
scatterplot3d(wt,disp,mpg, pch=carb, col=c(am),type="h", main="3D Scatterplot")
scatterplot3d(wt,disp,mpg, pch=carb, type="h", main="3D Scatterplot")
scatterplot3d(wt,disp,mpg, pch=carb, type="h", col="blue", main="3D Scatterplot")
corrgram(mtcars, order=TRUE, lower.panel=panel.shade,
plot3d(wt, mpg, disp, col=carb, size=5)
)
library(corrgram)
install.papckages("corrgram")
install.packages("corrgram")
library(corrgram)
main="Car Milage Data in PC2/PC1 Order")
corrgram(mtcars, order=TRUE, lower.panel=panel.shade,upper.panel=panel.pie, text.panel=panel.txt)
library(rgl)
attach(mtcars)
plot3d(wt, mpg, disp, col=carb, size=5)
str(mtcars)
plot3d(hp, mpg, cyl, col=carb, size=5)
plot3d(hp, mpg, cyl, col=gear, size=5)
plot3d(hp, mpg, am, col=cyl, size=5)
plot3d(hp, mpg, cyl, col=gear, size=5)
plot3d(hp, mpg, cyl, col=carb, size=8)
plot3d(hp, mpg, am, col=cyl, size=8)
corrgram(mtcars, order=TRUE,upper.panel=panel.pie, text.panel=panel.txt)
str(mtcars)
corrgram(mtcars, order=TRUE,upper.panel=panel.pie, text.panel=panel.txt)
corrgram(mtcars, order=TRUE, lower.panel=panel.shade,text.panel=panel.txt)
corrgram(mtcars, order=TRUE,upper.panel=panel.pie, text.panel=panel.txt)
corrgram(mtcars, order=TRUE,text.panel=panel.txt)
library(MASS)
fit <- lm(mpg~.,data=mtcars)
step <- stepAIC(fit, direction="both")
fit
step
step$nova
step$Nova
step$anova
library(leaps)
install.packages("leaps")
library(leaps)
leaps<-regsubsets(y~x1+x2+x3+x4,data=mydata,nbest=10)
leaps<-regsubsets(mpg~.,data=mt,nbest=10)
leaps<-regsubsets(mpg~.,data=mtcars,nbest=10)
summary(leaps)
summary(step)
step <- stepAIC(fit, direction="back")
DF<- read.csv("D:/Data/week2-HW-data.csv")
df
DF
model01 <- lm(SBP ~ AGE, data = DF)
model01 <- lm(SBP ~ AGE, data = DF)
model02 <- lm(SBP ~ SMK, data = DF)
model03 <- lm(SBP ~ SMK+QUET, data = DF)
summary(fit01)
summary(fit02)
summary(fit03)
fit01 <- lm(SBP ~ AGE, data = DF)
fit02 <- lm(SBP ~ SMK, data = DF)
fit03 <- lm(SBP ~ SMK+QUET, data = DF)
summary(fit01)
summary(fit02)
summary(fit03)
##Clear the environment
rm(list=ls())
##Turn off scientific notations for numbers
options(scipen = 999)
##Set locale
Sys.setlocale("LC_ALL", "English")
##Set seed for reproducibility
set.seed(2345)
##Function for pi
plot.add.pi <- function(x, y, interval='prediction', level=0.95, regressionColor='red', ...) {
xOrder  <- order(x)
x       <- x[xOrder]
y       <- y[xOrder]
fit     <- lm(y ~ x, data=data.frame(x=x, y=y))
newX    <- data.frame(x=jitter(x))
fitPred <- predict.lm(fit, newdata=newX, interval=interval, level=level, ...)
abline(lm(y ~ x), col=regressionColor)
lines(newX$x, fitPred[,2], lty=2, ...)
lines(newX$x, fitPred[,3], lty=2, ...)
}
##Function for ci
plot.add.ci <- function(x, y, interval='confidence', level=0.95, regressionColor='red', ...) {
xOrder  <- order(x)
x       <- x[xOrder]
y       <- y[xOrder]
fit     <- lm(y ~ x, data=data.frame(x=x, y=y))
newX    <- data.frame(x=jitter(x))
fitPred <- predict.lm(fit, newdata=newX, interval=interval, level=level, ...)
#abline(lm(y ~ x), col=regressionColor)
lines(newX$x, fitPred[,2], lty=2, ...)
lines(newX$x, fitPred[,3], lty=2, ...)
}
DF<- read.csv("D:/Data/week2-HW-data.csv")
summary(DF)
fit01 <- lm(SBP ~ AGE, data = DF)
fit02 <- lm(SBP ~ SMK, data = DF)
fit03 <- lm(SBP ~ SMK+QUET, data = DF)
summary(fit01)
summary(fit02)
summary(fit03)
fit01 <- lm(SBP ~ AGE, data = DF)
fit02 <- lm(SBP ~ AGE+SMK, data = DF)
fit03 <- lm(SBP ~ AGE+SMK+QUET, data = DF)
summary(fit01)
summary(fit02)
summary(fit03)
summary(lm(SBP ~ AGE+SMK, data = DF))$r.squared
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))pvalue
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$pvalue
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$p-value
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$p
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$F
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$f
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$f(,1)
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$f[,1]
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$f[1]
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$f[1]
str(summary(fit))
str(summary(fit1))
str(summary(fit01))
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$f
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$p
summary(lm(SBP ~ AGE+SMK+QUET, data = DF))$fp
summary(lm(SBP ~ AGE, data = DF))$fp
summary(lm(SBP ~ AGE, data = DF))$f
str(summary(fit01))
lmp <- function (modelobject) {
if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
f <- summary(modelobject)$fstatistic
p <- pf(f[1],f[2],f[3],lower.tail=F)
attributes(p) <- NULL
return(p)
}
lmp(fit01)
lmp(fit02)
lmp(fit03)
?summary
summary.lm
summary.lm(fit01)
?summary.lm
anova(fit1)
anova(fit01)
anova(fit01)$Pr
anova(fit01)$Pr[1]
anova(fit02)$Pr[1]
anova(fit03)$Pr[1]
predict.lm(fit02, interval="prediction")
predict.lm(fit02, interval="confidence")
confint(fit03)
confint(fit01)
confint(fit02)
vif(fit01)
library(car)
install.packages("car")
library(car)
vif(fit01)
vif(fit02)
vif(fit03)
1/vif(fit03)
#VIFs - requires car package
vif (fit02)
1/vif(fit02)
Multicollinearity is a phenomenon in which two or more predictor variables in a multiple regression model are highly correlated, meaning that one can be linearly predicted from the others with a non-trivial degree of accuracy.   A tolerance of less than 0.20 or 0.10 and/or a VIF of 5 or 10 and above indicates a multicollinearity problem.
newx <-c(50,1,3.5)
predict.lm(fit03, newx, interval="confidence")
predict.lm(fit03, newx)
newx <-c(50,0,3.5)
predict.lm(fit03, newx, interval="confidence")
predict(fit03,data.frame(AGE=50, SMK=0, QUET=3.5),interval="confidence")
predict(fit03,data.frame(AGE=50, SMK=0, QUET=3.5))
predict(fit03,data.frame(AGE=50, SMK=1, QUET=3.5))
predict(fit03,data.frame(AGE=50, SMK=0, QUET=3.5)) - predict(fit03,data.frame(AGE=50, SMK=0, QUET=3.0))
aov(fit01)
aov(fit01,fit02)
aov(fit02)
