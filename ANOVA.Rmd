---
title: "ANOVA"
author: "Dr. B"
date: "Saturday, October 11, 2014"
output: html_document
---
Assumptions of Analysis of Variance
------------------------------------
Traditional parametric analysis of variance makes the following assumptions:

Random sampling, or at the very least, random assignment to groups.
Independence of scores on the response variable -- i.e., what you get from one subject should be in no way influenced by what you get from any of the others.
Sampling from normal populations within each cell of the design.
Homogeneity of variance -- the populations within each cell of the design should all have the same variance.

The last two are assumptions we need to look at statistically.

Variables
------------
Types of Variables Determine Type of Model

The explanatory variables
        All continuous                  Regression
        All categorical                 Analysis of variance (Anova)
        Both continuousand categorical  Analysis of covariance (Ancova)
        
The response variable
        Continuous                      Normal Regression, Anova, Ancova
        Proportion                      Logistic regression
        Count                           Log linear models
        Binary                          Binary logistic analysis
        Time-at-death                   Survival analysis

The Oneway ANOVA
----------------
One-way analysis of variance (ANOVA) is a technique used to compare means of two or more samples using the F distribution. The ANOVA tests the null hypothesis that samples in two or more groups are drawn from populations with the same mean values. To do this, two estimates are made of the population variance. These estimates rely on various assumptions (see below). The ANOVA produces an F-statistic, the ratio of the variance calculated among the means to the variance within the samples. If the group means are drawn from populations with the same mean values, the variance between the group means should be lower than the variance of the samples. A higher ratio implies that the samples were drawn from populations with different mean values.

On of the simpliest wways to perform an analysis of variance is to use the oneway.test( ) function for simple between subjects designs. 

The data are from an agricultural experiment in which six different insect sprays were tested in many different fields, and the response variable (DV) was a count of insects found in each field after spraying.
```{r,message=FALSE,warning=FALSE}
##Use my standard openning including call function
if (Sys.info()["sysname"]=="Linux"){
  source('/home/bryan/GitHub/MyWork/StdOpen.R')     
}else{
  source('C:/Users/bryan_000/Documents/GitHub/MyWork/StdOpen.R')   
}

call("lawstat")

data(InsectSprays)
attach(InsectSprays)
tapply(count, spray, mean)
tapply(count, spray, var)
tapply(count, spray, length)
```

There are large differences in the means, but there are also large differences in the variances (and worse yet, the means and variances appear to be related). At least the design is balanced. Boxplots are a good way to present the data graphically... 
```{r, echo=FALSE}
boxplot(count ~ spray)
abline(h=mean(count), col="Red")
```

###The aov( ) Function
The standard R function for all kinds of ANOVA is aov( ). The general form is aov(response ~ factor, data=data_name).  It's best to store the output of this function and then to extract the information you want by way of various extractor functions.
```{r}
output <- aov(count ~ spray)
model.tables(output,"means")
summary(output)
plot(output)
```

###Post Hoc Tests
####Pairwise T Test
The function pairwise.t.test computes the pair-wise comparisons between group means with corrections for multiple testing. The general form is pairwise.t.test(reponse, factor, p.adjust = method, alternative = c("two.sided","less", "greater"))
```{r}
pairwise.t.test(count, spray,  p.adjust="bonferroni")
```

####Tukey Honestly Significant Difference
Post hoc tests are designed for situations in which the researcher has already obtained
a significant omnibus F-test with a factor that consists of three or more means and additional exploration of the differences among means is needed to provide specific information on which means are significantly different from each other.  The Tukey Honestly Significant Difference test has been implemented in the R base distribution as the default post hoc test for ANOVA. It's easily enough applied once the output of aov( ) has been stored in a data object.  The procedure prints out the difference between means for each pair of groups, the lower and upper limits of a 95% confidence interval for that difference (change this by setting the "conf.level=" option), and the p-value for the Tukey test.  The general form is TukeyHSD(x, conf.level = 0.95)

```{r}
TukeyHSD(output)
plot(TukeyHSD(output))
```

###oneway.test( ) 
By default, the oneway.test( ) applies a Welch correction for nonhomogeneity.  If you want to turn off this behavior, set the "var.equal=" option to TRUE.  By default, The oneway.test( ) function is to omit missing values. This means you should check your data for missing values before hand, as this procedure will not tell you about them if they exist.  You can add na.action="na.fail" to cause the function to fail it there are missing values.
```{r}
oneway.test(count ~ spray)
```

###Testing For Homogeneity of Variance
####Bartlett's Test
Bartlett's test is used to test if k samples are from populations with equal variances. Equal variances across samples is called homoscedasticity or homogeneity of variances. Bartlett's test is used to test the null hypothesis that all k population variances are equal against the alternative that at least two are different.
```{r}
bartlett.test(count ~ spray, data=InsectSprays)
```

####Levene's Test
Levene's test is used to test if k samples have equal variances. Equal variances across samples is called homogeneity of variance. Some statistical tests, for example the analysis of variance, assume that variances are equal across groups or samples. The Levene test can be used to verify that assumption.  Levene's test is an alternative to the Bartlett test. The Levene test is less sensitive than the Bartlett test to departures from normality. If you have strong evidence that your data do in fact come from a normal, or nearly normal, distribution, then Bartlett's test has better performance.
```{r}
#call("lawstat")
levene.test(InsectSprays$count,InsectSprays$spray)
```
###Testing For Normality in One Way ANOVA
The Shapiro test can be used to check the normality assumption for ANOVA F-test. When testing for normality, the null hypothesis is that the data are normally distributed; the alternative hypothesis is that the data are non-normal; therefore, if the p-value is less than a chosen alpha, then reject the null hypothesis that the data come from that distribution.  
```{r}
by(InsectSprays$count, InsectSprays$spray, shapiro.test)
```

###Kruskal-Wallis oneway ANOVA
A nonparametric test is often used when the normality assummption of ANOVA fails.  The Kruskal-Wallis one-way analysis of variance by ranks is a non-parametric method for testing whether samples originate from the same distribution.  It is used for comparing two or more samples that are independent, and that may have different sample sizes, and extends the Mann-Whitney U test to more than two groups.  Since it is a non-parametric method, the Kruskal-Wallis test does not assume a normal distribution of the residuals, unlike the analogous one-way analysis of variance. 
```{r}
kruskal.test(count ~ spray, data=InsectSprays)
```
